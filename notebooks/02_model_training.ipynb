{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27184642",
   "metadata": {},
   "source": [
    "# 02 - Model Training and Walk-Forward\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "- Build training tensors from OHLCV data\n",
    "- Train LSTM / TCN / Transformer models\n",
    "- Run a simple walk-forward backtest\n",
    "- Inspect basic performance metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3906b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /home/giorgos/Desktop/AlphaFactory exists? True\n",
      "ROOT/research exists? True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "print(\"ROOT:\", ROOT, \"exists?\", ROOT.exists())\n",
    "print(\"ROOT/research exists?\", (ROOT / \"research\").exists())\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56a7a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    datetime64[ns]\n",
      "open                 object\n",
      "high                 object\n",
      "low                  object\n",
      "close                object\n",
      "volume               object\n",
      "dtype: object\n",
      "   timestamp                open                high                 low  \\\n",
      "0 2015-01-02   24.69423503534699   24.70532029541843   23.79860048379208   \n",
      "1 2015-01-05  24.006990190147395    24.0867993234754  23.368518814896508   \n",
      "2 2015-01-06   23.61903255400942  23.816338020280458   23.19560061965636   \n",
      "3 2015-01-07   23.76535220011818   23.98704392471396   23.65450633782029   \n",
      "4 2015-01-08   24.21537773680298  24.862716897095112  24.097879750947854   \n",
      "\n",
      "                close     volume  \n",
      "0  24.237550735473633  212818400  \n",
      "1  23.554738998413086  257142000  \n",
      "2   23.55695915222168  263188400  \n",
      "3  23.887283325195312  160423600  \n",
      "4  24.805076599121094  237458000  \n",
      "open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume    float64\n",
      "dtype: object\n",
      "        open       high        low      close       volume\n",
      "0  24.694235  24.705320  23.798600  24.237551  212818400.0\n",
      "1  24.006990  24.086799  23.368519  23.554739  257142000.0\n",
      "2  23.619033  23.816338  23.195601  23.556959  263188400.0\n",
      "3  23.765352  23.987044  23.654506  23.887283  160423600.0\n",
      "4  24.215378  24.862717  24.097880  24.805077  237458000.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from research.common import load_ohlcv_csv, BarConfig\n",
    "from research.feature_engineering import FeatureConfig, build_features\n",
    "from research.model_lstm import LSTMAlpha, LSTMConfig, train_lstm\n",
    "from research.model_tcn import TCNAlpha, TCNConfig, train_tcn\n",
    "from research.model_transformer import TransformerAlpha, TransformerConfig, train_transformer\n",
    "from research.walk_forward import WalkForwardConfig, walk_forward\n",
    "from research.evaluation import aggregate_walk_forward\n",
    "\n",
    "DATA_PATH = pathlib.Path(\"../data/equities/AAPL.csv\")\n",
    "\n",
    "raw = load_ohlcv_csv(str(DATA_PATH))\n",
    "print(raw.dtypes)\n",
    "print(raw.head())\n",
    "num_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "# Strip whitespace and force numeric for each, turning bad values into NaN\n",
    "for c in num_cols:\n",
    "    raw[c] = (\n",
    "        raw[c]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\", regex=False)  # drop thousands separators if any\n",
    "        .str.strip()\n",
    "    )\n",
    "    raw[c] = pd.to_numeric(raw[c], errors=\"coerce\")\n",
    "\n",
    "# Drop any rows where OHLCV is missing\n",
    "raw = raw.dropna(subset=num_cols).reset_index(drop=True)\n",
    "\n",
    "print(raw[num_cols].dtypes)\n",
    "print(raw[num_cols].head())\n",
    "\n",
    "bar_cfg = BarConfig(lookback_window=128, prediction_horizon=5)\n",
    "feat_cfg = FeatureConfig(bar=bar_cfg)\n",
    "X, y, feature_cols = build_features(raw, feat_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e82a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model family here: \"lstm\", \"tcn\", or \"transformer\"\n",
    "MODEL_FAMILY = \"lstm\"\n",
    "\n",
    "n_features = X.shape[-1]\n",
    "len(X)\n",
    "\n",
    "\n",
    "def train_fn(train_data, val_data):\n",
    "    X_train, y_train = train_data\n",
    "    X_val, y_val = val_data\n",
    "\n",
    "    if MODEL_FAMILY == \"lstm\":\n",
    "        cfg = LSTMConfig(input_size=n_features)\n",
    "        model = LSTMAlpha(cfg)\n",
    "        return train_lstm(model, (X_train, y_train), (X_val, y_val), epochs=5)\n",
    "    elif MODEL_FAMILY == \"tcn\":\n",
    "        cfg = TCNConfig(input_size=n_features)\n",
    "        model = TCNAlpha(cfg)\n",
    "        return train_tcn(model, (X_train, y_train), (X_val, y_val), epochs=5)\n",
    "    elif MODEL_FAMILY == \"transformer\":\n",
    "        cfg = TransformerConfig(input_size=n_features)\n",
    "        model = TransformerAlpha(cfg)\n",
    "        return train_transformer(model, (X_train, y_train), (X_val, y_val), epochs=5)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown MODEL_FAMILY={MODEL_FAMILY}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e93935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 19\n"
     ]
    }
   ],
   "source": [
    "from research.walk_forward import WalkForwardConfig, walk_forward\n",
    "\n",
    "wf_cfg = WalkForwardConfig(window_train=500, window_val=100, step=100)  # smaller windows if data is short\n",
    "wf_results = walk_forward(X, y, wf_cfg, train_fn)\n",
    "\n",
    "print(type(wf_results), len(wf_results))  # should be <class 'list'> and > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce57285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceStats(sharpe=0.04586688453656595, sortino=0.05724832066001501, max_drawdown=-0.7789467573165894, mean=3.4980035707121715e-05, vol=0.012106574140489101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = aggregate_walk_forward(wf_results)\n",
    "stats = summary[\"stats\"]\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f47e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wf_results to ../signals/signal_files/wf_results.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "OUT_PATH = Path(\"../signals/signal_files/wf_results.pkl\")\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(OUT_PATH, \"wb\") as f:\n",
    "    pickle.dump(wf_results, f)\n",
    "\n",
    "print(\"Saved wf_results to\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca8d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved positions CSV to ../signals/signal_files/positions_example.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "positions = summary[\"positions\"]      # strategy target positions over time\n",
    "returns_series = summary[\"y_true\"]    # underlying returns (used to build a dummy price)\n",
    "\n",
    "# Build a synthetic price series from underlying returns, starting at 100\n",
    "price = 100 * (1 + pd.Series(returns_series)).cumprod()\n",
    "\n",
    "pos_df = pd.DataFrame({\n",
    "    \"timestamp\": pd.date_range(\"2000-01-01\", periods=len(positions), freq=\"D\"),\n",
    "    \"price\": price.values,\n",
    "    \"target_position\": positions,\n",
    "})\n",
    "\n",
    "pos_path = \"../signals/signal_files/positions_example.csv\"\n",
    "pos_df.to_csv(pos_path, index=False)\n",
    "print(\"Saved positions CSV to\", pos_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f4ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote signals to signals/signal_files/alpha_ml_signals.csv\n"
     ]
    }
   ],
   "source": [
    "from signals.signal_exporter import export_signals\n",
    "\n",
    "timestamps = pd.date_range(\"2015-01-01\", periods=len(summary[\"y_pred\"]), freq=\"D\")\n",
    "asset_ids = [\"AAPL\"]\n",
    "scores = summary[\"y_pred\"].reshape(-1, 1)  # shape [T, N]\n",
    "\n",
    "export_path = export_signals(timestamps, asset_ids, scores)\n",
    "print(\"Wrote signals to\", export_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
